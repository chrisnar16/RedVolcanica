{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Red.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOUYKPA3j4YL4YuDIbxwq8x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhg4evFt81xb","executionInfo":{"status":"ok","timestamp":1637262777484,"user_tz":300,"elapsed":25407,"user":{"displayName":"Christian Mauricio Yépez Escalante","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPAU1qTofut__rEh6qCzvBRAI1UOFlzBDDQOqKIA=s64","userId":"15071697346296237740"}},"outputId":"96a9be0a-b88e-4b9c-b55a-7e845abe33d3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","py_file_location = \"/content/drive/MyDrive/Tesis/Git/RedVolcanica\"\n","%cd \"{py_file_location}\" "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Tesis/Git/RedVolcanica\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ti01SFhJ9mzS","executionInfo":{"status":"ok","timestamp":1637262823372,"user_tz":300,"elapsed":30009,"user":{"displayName":"Christian Mauricio Yépez Escalante","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPAU1qTofut__rEh6qCzvBRAI1UOFlzBDDQOqKIA=s64","userId":"15071697346296237740"}},"outputId":"a96cc6e4-a2b0-45e4-f199-6b9b3a4f0645"},"source":["import importlib\n","\n","import RedFunciones.visualizacion as visualizacion\n","import RedFunciones.Generador as Generador\n","import RedFunciones.Discriminador as Discriminador\n","import RedFunciones.auxiliares as auxiliares\n","import RedFunciones.DataloaderVol as DataloaderVol\n","import RedFunciones.Checkpoint as Checkpoint\n","\n","importlib.reload(auxiliares)\n","importlib.reload(Generador)\n","importlib.reload(Discriminador)\n","importlib.reload(DataloaderVol)\n","importlib.reload(Checkpoint)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'RedFunciones.Checkpoint' from '/content/drive/MyDrive/Tesis/Git/RedVolcanica/RedFunciones/Checkpoint.py'>"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"d-u2HlmUUDqF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637262831711,"user_tz":300,"elapsed":168,"user":{"displayName":"Christian Mauricio Yépez Escalante","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPAU1qTofut__rEh6qCzvBRAI1UOFlzBDDQOqKIA=s64","userId":"15071697346296237740"}},"outputId":"286a1f90-88a5-4033-ad91-4c8e097a130a"},"source":["import torch\n","from torch import nn\n","\n","from tqdm.auto import tqdm # Progress bar\n","\n","from torchvision import transforms\n","from torchvision.utils import make_grid\n","from torchvision.datasets import MNIST #noned\n","\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","\n","torch.manual_seed(0) # Set for our testing purposes, please do not change!\n","\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f099f70e490>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"4wj4N812F0H-"},"source":["criterion: the loss function\n","\n","n_epochs: the number of times you iterate through the entire \n","dataset when training\n","\n","z_dim: the dimension of the noise vector\n","\n","display_step: how often to display/visualize the images\n","\n","batch_size: the number of images per forward/backward pass\n","\n","lr: the learning rate\n","\n","device: the device type"]},{"cell_type":"code","metadata":{"id":"3yenniLFFfEP"},"source":["mnist_shape = (1, 129, 33) #tamaño imagen\n","n_classes = 2 # numkero etiquetas\n","cuda0 = torch.device('cuda:0')\n","cpu = 'cpu'\n","\n","device = torch.device(cuda0 if torch.cuda.is_available() else cpu)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","n_epochs = 1\n","z_dim = 64\n","display_step = 1\n","batch_size = 25\n","lr = 0.0002\n","\n","nombre = 'master'\n","nombre_carga = 'master-2021-11-18.pt'\n","guardar = True\n","cargar = False\n","save_steep = 1\n","\n","epoch_temp = -1\n","gen_loss_temp = torch.empty([])\n","disc_loss_temp = torch.empty([]) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eh7DtKHEHTY3"},"source":["#cargar datos\n","dir_nam = '/content/drive/MyDrive/Tesis/Red/basedesglosada/'\n","json_nam = '/content/drive/MyDrive/Tesis/Red/data.json'\n","h5_filename = '/content/drive/MyDrive/Tesis/Git/RedVolcanica/baseh5/data1.h5'\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,)),\n","])\n","\n","myData = DataloaderVol.VolcanoDatasetH5(h5_filename, transform)\n","\n","dataloader = DataLoader(\n","    myData,\n","    batch_size=batch_size,\n","    shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCU_Hi1dzff9"},"source":["# New Section"]},{"cell_type":"code","metadata":{"id":"BQRA9L7sJVPU"},"source":["generator_input_dim, discriminator_im_chan = auxiliares.get_input_dimensions(z_dim, mnist_shape, n_classes)\n","\n","gen = Generador.Generator(input_dim=generator_input_dim).to(device)\n","gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n","disc = Discriminador.Discriminator(im_chan=discriminator_im_chan).to(device)\n","disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n","\n","gen = gen.apply(auxiliares.weights_init)\n","disc = disc.apply(auxiliares.weights_init)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uwf8nslcSBWF"},"source":["if cargar:\n","  compelto = Checkpoint.DIRECTORY + nombre_carga\n","  checkpoint = torch.load(compelto)\n","  gen.load_state_dict(checkpoint['gen'])\n","  disc.load_state_dict(checkpoint['disc'])\n","  gen_opt.load_state_dict(checkpoint['gen_opt'])\n","  disc_opt.load_state_dict(checkpoint['disc_opt'])\n","  epoch_temp = checkpoint['epoch']\n","  gen_loss_temp = checkpoint['gen_loss']\n","  disc_loss_temp = checkpoint['dis_loss']\n","  print('Modelo cargado')\n","  print('epoch: ' + str(epoch_temp))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5dKjX-BpKq2s"},"source":["cur_step = 0\n","generator_losses = []\n","discriminator_losses = []\n","\n","for epoch in range(epoch_temp + 1, n_epochs):\n","    print('Epoch: ' + str(epoch))\n","    # Dataloader returns the batches and the labels\n","    for real, labels in tqdm(dataloader):\n","        cur_batch_size = len(real)\n","        # Flatten the batch of real images from the dataset\n","        real = real.unsqueeze(1)\n","        real = real.to(device)\n","\n","        one_hot_labels = auxiliares.get_one_hot_labels(labels.to(device), n_classes)\n","        image_one_hot_labels = one_hot_labels[:, :, None, None]\n","        image_one_hot_labels = image_one_hot_labels.repeat(1, 1, mnist_shape[1], mnist_shape[2])\n","\n","        ### Update discriminator ###\n","        # Zero out the discriminator gradients\n","        disc_opt.zero_grad()\n","        # Get noise corresponding to the current batch_size \n","        fake_noise = auxiliares.get_noise(cur_batch_size, z_dim, device=device)\n","        \n","        # Now you can get the images from the generator\n","        # Steps: 1) Combine the noise vectors and the one-hot labels for the generator\n","        #        2) Generate the conditioned fake images\n","       \n","        noise_and_labels = auxiliares.combine_vectors(fake_noise, one_hot_labels)\n","        fake = gen(noise_and_labels)#gen.forward(noise_and_labels) no usar\n","\n","        # Now you can get the predictions from the discriminator\n","        # Steps: 1) Create the input for the discriminator\n","        #           a) Combine the fake images with image_one_hot_labels, \n","        #              remember to detach the generator (.detach()) so you do not backpropagate through it\n","        #           b) Combine the real images with image_one_hot_labels\n","        #        2) Get the discriminator's prediction on the fakes as disc_fake_pred\n","        #        3) Get the discriminator's prediction on the reals as disc_real_pred\n","        \n","        fake_image_and_labels = auxiliares.combine_vectors(fake.detach(), image_one_hot_labels)\n","        real_image_and_labels = auxiliares.combine_vectors(real, image_one_hot_labels)\n","        disc_fake_pred = disc(fake_image_and_labels)\n","        disc_real_pred = disc(real_image_and_labels)       \n","        \n","        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n","        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n","        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n","        disc_loss.backward(retain_graph=True)\n","        disc_opt.step() \n","\n","        # Keep track of the average discriminator loss\n","        discriminator_losses += [disc_loss.item()]\n","\n","        ### Update generator ###\n","        # Zero out the generator gradients\n","        gen_opt.zero_grad()\n","\n","        fake_image_and_labels = auxiliares.combine_vectors(fake, image_one_hot_labels)\n","        # This will error if you didn't concatenate your labels to your image correctly\n","        disc_fake_pred = disc(fake_image_and_labels)\n","        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n","        gen_loss.backward()\n","        gen_opt.step()\n","\n","        # Keep track of the generator losses\n","        generator_losses += [gen_loss.item()]\n","        #\n","\n","        if cur_step % display_step == 0 and cur_step > 0:\n","            gen_mean = sum(generator_losses[-display_step:]) / display_step\n","            disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n","            print(f\"Step {cur_step}: Generator loss: {gen_mean}, discriminator loss: {disc_mean}\")\n","            visualizacion.show_tensor_images(torch.swapaxes(fake, 2, 3), size=(1, 129, 33))\n","            visualizacion.show_tensor_images(torch.swapaxes(real, 2, 3), size=(1, 129, 33))\n","            step_bins = 20\n","            x_axis = sorted([i * step_bins for i in range(len(generator_losses) // step_bins)] * step_bins)\n","            num_examples = (len(generator_losses) // step_bins) * step_bins\n","            plt.plot(\n","                range(num_examples // step_bins), \n","                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n","                label=\"Generator Loss\"\n","            )\n","            plt.plot(\n","                range(num_examples // step_bins), \n","                torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n","                label=\"Discriminator Loss\"\n","            )\n","            plt.legend()\n","            plt.show()\n","        elif cur_step == 0:\n","            print(\"Red Funcionando\")\n","        cur_step += 1 \n","    if((guardar and epoch % save_steep == 0) or epoch == n_epochs - 1):\n","        Checkpoint.save_weighs(gen, disc, gen_opt, disc_opt, epoch, gen_loss, disc_loss, nombre)\n","        print('epoch guardada')                "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IvMQtgGa_x6B"},"source":["print(gen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gT-QnN2u-rvp"},"source":["#gen.state_dict()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RwDyX-xl7m1C","executionInfo":{"status":"ok","timestamp":1637264389790,"user_tz":300,"elapsed":230,"user":{"displayName":"Christian Mauricio Yépez Escalante","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPAU1qTofut__rEh6qCzvBRAI1UOFlzBDDQOqKIA=s64","userId":"15071697346296237740"}},"outputId":"e3fd1dd2-3e2e-4651-e897-42421be9da0d"},"source":["from torchvision import models\n","from torchsummary import summary\n","\n","summary(gen, (66,1,1))\n","\n","summary(disc, (3,129,33))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","   ConvTranspose2d-1            [-1, 256, 5, 3]         253,696\n","       BatchNorm2d-2            [-1, 256, 5, 3]             512\n","              ReLU-3            [-1, 256, 5, 3]               0\n","   ConvTranspose2d-4           [-1, 128, 10, 6]         786,560\n","       BatchNorm2d-5           [-1, 128, 10, 6]             256\n","              ReLU-6           [-1, 128, 10, 6]               0\n","   ConvTranspose2d-7           [-1, 64, 24, 14]         196,672\n","       BatchNorm2d-8           [-1, 64, 24, 14]             128\n","              ReLU-9           [-1, 64, 24, 14]               0\n","  ConvTranspose2d-10           [-1, 32, 52, 30]          49,184\n","      BatchNorm2d-11           [-1, 32, 52, 30]              64\n","             ReLU-12           [-1, 32, 52, 30]               0\n","  ConvTranspose2d-13           [-1, 1, 129, 33]           3,457\n","             Tanh-14           [-1, 1, 129, 33]               0\n","================================================================\n","Total params: 1,290,529\n","Trainable params: 1,290,529\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 1.96\n","Params size (MB): 4.92\n","Estimated Total Size (MB): 6.89\n","----------------------------------------------------------------\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 63, 15]           3,904\n","       BatchNorm2d-2           [-1, 64, 63, 15]             128\n","         LeakyReLU-3           [-1, 64, 63, 15]               0\n","            Conv2d-4           [-1, 128, 30, 6]         163,968\n","       BatchNorm2d-5           [-1, 128, 30, 6]             256\n","         LeakyReLU-6           [-1, 128, 30, 6]               0\n","            Conv2d-7              [-1, 1, 1, 1]          23,041\n","================================================================\n","Total params: 191,297\n","Trainable params: 191,297\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.05\n","Forward/backward pass size (MB): 1.91\n","Params size (MB): 0.73\n","Estimated Total Size (MB): 2.69\n","----------------------------------------------------------------\n"]}]}]}