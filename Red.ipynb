{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhg4evFt81xb"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    py_file_location = \"/content/drive/MyDrive/Tesis/Git/RedVolcanica\"\n",
    "    %cd \"{py_file_location}\" \n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "print(IN_COLAB)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ti01SFhJ9mzS"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import RedFunciones.visualizacion as visualizacion\n",
    "import RedFunciones.Generador as Generador\n",
    "import RedFunciones.Discriminador as Discriminador\n",
    "import RedFunciones.auxiliares as auxiliares\n",
    "import RedFunciones.DataloaderVol as DataloaderVol\n",
    "import RedFunciones.Checkpoint as Checkpoint\n",
    "\n",
    "importlib.reload(auxiliares)\n",
    "importlib.reload(visualizacion)\n",
    "importlib.reload(Generador)\n",
    "importlib.reload(Discriminador)\n",
    "importlib.reload(DataloaderVol)\n",
    "importlib.reload(Checkpoint)\n",
    "\n",
    "import Auxiliares.BinaryAccuracy as bin_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1638463916202,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPAU1qTofut__rEh6qCzvBRAI1UOFlzBDDQOqKIA=s64",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "d-u2HlmUUDqF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchaudio\n",
    "\n",
    "from tqdm.auto import tqdm # Progress bar\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import MNIST #noned\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0) # Set for our testing purposes, please do not change!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2XDqS-EDm3Q",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5T2lKzKDm3W"
   },
   "source": [
    "criterion: the loss function\n",
    "\n",
    "n_epochs: the number of times you iterate through the entire \n",
    "dataset when training\n",
    "\n",
    "z_dim: the dimension of the noise vector\n",
    "\n",
    "display_step: how often to display/visualize the images\n",
    "\n",
    "batch_size: the number of images per forward/backward pass\n",
    "\n",
    "lr: the learning rate\n",
    "\n",
    "device: the device type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 168,
     "status": "ok",
     "timestamp": 1638463921234,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPAU1qTofut__rEh6qCzvBRAI1UOFlzBDDQOqKIA=s64",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "3yenniLFFfEP"
   },
   "outputs": [],
   "source": [
    "mnist_shape = (1, 129, 33) #tamaño imagen\n",
    "n_classes = 2 # numkero etiquetas\n",
    "cuda0 = torch.device('cuda:0')\n",
    "cpu = 'cpu'\n",
    "\n",
    "device = torch.device(cuda0 if torch.cuda.is_available() else cpu)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 1\n",
    "z_dim = 64\n",
    "display_step = 250\n",
    "batch_size = 16\n",
    "lrg = 0.0001\n",
    "lrd = 0.0004\n",
    "nombre = 'master'\n",
    "nombre_carga = 'master-2021-11-18.pt'\n",
    "guardar = True\n",
    "cargar = False\n",
    "save_steep = 1\n",
    "\n",
    "epoch_temp = -1\n",
    "gen_loss_temp = torch.empty([])\n",
    "disc_loss_temp = torch.empty([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 12.0708\n",
    "std = 51.3166\n",
    "mean_p = False\n",
    "if mean_p:\n",
    "    dir_nam = cwd + '/basedesglosada/'\n",
    "    json_nam = cwd + '/data.json'\n",
    "    h5_filename = cwd + '/baseh5/data2.h5'\n",
    "    myDataA = DataloaderVol.VolcanoDatasetH5(h5_filename)\n",
    "    dataloaderA = DataLoader(\n",
    "        myDataA,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "    def get_mean_and_std(dataloader):\n",
    "        channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "        for data, _ in dataloader:\n",
    "            # Mean over batch, height and width, but not over the channels\n",
    "            channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "            channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "            num_batches += 1    \n",
    "        mean = channels_sum / num_batches\n",
    "        # std = sqrt(E[X^2] - (E[X])^2)\n",
    "        std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "        return mean, std\n",
    "\n",
    "    mean, std = get_mean_and_std(dataloaderA)\n",
    "    print(mean)\n",
    "    print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1638464255430,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPAU1qTofut__rEh6qCzvBRAI1UOFlzBDDQOqKIA=s64",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "eh7DtKHEHTY3"
   },
   "outputs": [],
   "source": [
    "#cargar datos\n",
    "dir_nam = cwd + '/basedesglosada/'\n",
    "json_nam = cwd + '/data.json'\n",
    "h5_filename = cwd + '/baseh5/data2.h5'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    #transforms.ToTensor(),\n",
    "    transforms.Normalize((mean,), (std,)),\n",
    "    #torchaudio.transforms.MelScale(sample_rate=50, n_stft=129)\n",
    "])\n",
    "\n",
    "myData = DataloaderVol.VolcanoDatasetH5(h5_filename, transform)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    myData,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1638464258158,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPAU1qTofut__rEh6qCzvBRAI1UOFlzBDDQOqKIA=s64",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "BQRA9L7sJVPU"
   },
   "outputs": [],
   "source": [
    "generator_input_dim, discriminator_im_chan = auxiliares.get_input_dimensions(z_dim, mnist_shape, n_classes)\n",
    "\n",
    "gen = Generador.Generator(input_dim=generator_input_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lrg)\n",
    "disc = Discriminador.Discriminator(im_chan=discriminator_im_chan).to(device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lrd)\n",
    "gen = gen.apply(auxiliares.weights_init)\n",
    "disc = disc.apply(auxiliares.weights_init)\n",
    "\n",
    "gen.train()\n",
    "disc.train()\n",
    "        \n",
    "metric = bin_acc.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1638464260518,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPAU1qTofut__rEh6qCzvBRAI1UOFlzBDDQOqKIA=s64",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "Uwf8nslcSBWF"
   },
   "outputs": [],
   "source": [
    "if cargar:\n",
    "    compelto = Checkpoint.DIRECTORY + nombre_carga\n",
    "    checkpoint = torch.load(compelto)\n",
    "    gen.load_state_dict(checkpoint['gen'])\n",
    "    disc.load_state_dict(checkpoint['disc'])\n",
    "    gen_opt.load_state_dict(checkpoint['gen_opt'])\n",
    "    disc_opt.load_state_dict(checkpoint['disc_opt'])\n",
    "    epoch_temp = checkpoint['epoch']\n",
    "    gen_loss_temp = checkpoint['gen_loss']\n",
    "    disc_loss_temp = checkpoint['dis_loss']\n",
    "    print('Modelo cargado')\n",
    "    print('epoch: ' + str(epoch_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dKjX-BpKq2s",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cur_step = 0\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "metric_real = []\n",
    "metric_fake = [] \n",
    "\n",
    "for epoch in range(epoch_temp + 1, n_epochs):\n",
    "    print('Epoch: ' + str(epoch))\n",
    "    # Dataloader returns the batches and the labels\n",
    "    for real, labels in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        # Flatten the batch of real images from the dataset\n",
    "        real = real.to(device)\n",
    "\n",
    "        one_hot_labels = auxiliares.get_one_hot_labels(labels.to(device), n_classes)\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = image_one_hot_labels.repeat(1, 1, mnist_shape[1], mnist_shape[2])\n",
    "\n",
    "        ### Update discriminator ###\n",
    "        # Zero out the discriminator gradients\n",
    "        disc_opt.zero_grad()\n",
    "        # Get noise corresponding to the current batch_size \n",
    "        fake_noise = auxiliares.get_noise(cur_batch_size, z_dim, device=device)\n",
    "        \n",
    "        # Now you can get the images from the generator\n",
    "        # Steps: 1) Combine the noise vectors and the one-hot labels for the generator\n",
    "        #        2) Generate the conditioned fake images\n",
    "       \n",
    "        noise_and_labels = auxiliares.combine_vectors(fake_noise, one_hot_labels)\n",
    "        fake = gen(noise_and_labels)#gen.forward(noise_and_labels) no usar\n",
    "\n",
    "        # Now you can get the predictions from the discriminator\n",
    "        # Steps: 1) Create the input for the discriminator\n",
    "        #           a) Combine the fake images with image_one_hot_labels, \n",
    "        #              remember to detach the generator (.detach()) so you do not backpropagate through it\n",
    "        #           b) Combine the real images with image_one_hot_labels\n",
    "        #        2) Get the discriminator's prediction on the fakes as disc_fake_pred\n",
    "        #        3) Get the discriminator's prediction on the reals as disc_real_pred\n",
    "        \n",
    "        fake_image_and_labels = auxiliares.combine_vectors(fake.detach(), image_one_hot_labels)\n",
    "        real_image_and_labels = auxiliares.combine_vectors(real, image_one_hot_labels)\n",
    "        disc_fake_pred = disc(fake_image_and_labels)\n",
    "        disc_real_pred = disc(real_image_and_labels)               \n",
    "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "\n",
    "        metric_fake += [metric(disc_fake_pred, torch.zeros_like(disc_fake_pred)).item()]\n",
    "        metric_real += [metric(disc_real_pred, torch.ones_like(disc_real_pred)).item()]\n",
    "        \n",
    "        #Reg\n",
    "        \n",
    "        reg_lambda = 0.001\n",
    "        l2_reg = None\n",
    "        for W in disc.parameters():\n",
    "            if l2_reg is None:\n",
    "                l2_reg = W.norm(2)\n",
    "            else:\n",
    "                l2_reg = l2_reg + W.norm(2)\n",
    "        \n",
    "        disc_loss = ((disc_fake_loss + disc_real_loss)/2) # + l2_reg * reg_lambda\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        disc_opt.step() \n",
    "\n",
    "        # Keep track of the average discriminator loss\n",
    "        discriminator_losses += [disc_loss.item()]\n",
    "\n",
    "        ### Update generator ###\n",
    "        # Zero out the generator gradients\n",
    "        gen_opt.zero_grad()\n",
    "\n",
    "        fake_image_and_labels = auxiliares.combine_vectors(fake, image_one_hot_labels)\n",
    "        # This will error if you didn't concatenate your labels to your image correctly\n",
    "        disc_fake_pred = disc(fake_image_and_labels)\n",
    "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Keep track of the generator losses\n",
    "        generator_losses += [gen_loss.item()]\n",
    "        #\n",
    "\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "            disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n",
    "            print(f\"Step {cur_step}: Generator loss: {gen_mean}, discriminator loss: {disc_mean}\")\n",
    "            visualizacion.show_tensor_images(torch.transpose(fake, 2, 3), size=(1, 129, 33))\n",
    "            visualizacion.show_tensor_images(torch.transpose(real, 2, 3), size=(1, 129, 33))\n",
    "            visualizacion.show_time_domine_images(torch.transpose(real, 2, 3), size=(1, 129, 33), std=std, mean=mean, real = True)\n",
    "            visualizacion.show_time_domine_images(torch.transpose(fake, 2, 3), size=(1, 129, 33), std=std, mean=mean, real = False)\n",
    "            step_bins = 20\n",
    "            x_axis = sorted([i * step_bins for i in range(len(generator_losses) // step_bins)] * step_bins)\n",
    "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Generator Loss\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Discriminator Loss\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(metric_real[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"METRIC REAL\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(metric_fake[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"METRIC FAKE\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        elif cur_step == 0:\n",
    "            print(\"Red Funcionando\")\n",
    "        cur_step += 1 \n",
    "    if((guardar and epoch % save_steep == 0) or epoch == n_epochs - 1):\n",
    "        Checkpoint.save_weighs(gen, disc, gen_opt, disc_opt, epoch, gen_loss, disc_loss, nombre)\n",
    "        print('epoch guardada')                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gT-QnN2u-rvp"
   },
   "outputs": [],
   "source": [
    "#gen.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1638462894146,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPAU1qTofut__rEh6qCzvBRAI1UOFlzBDDQOqKIA=s64",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "RwDyX-xl7m1C",
    "outputId": "3f5322ce-e25e-4c41-fa77-8b4d26b242b3"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(gen, (66,1,1))\n",
    "\n",
    "summary(disc, (3,129,33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.eval()\n",
    "disc.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PrePross.grifflin as grifflin\n",
    "import numpy as np\n",
    "\n",
    "examples = 1\n",
    "\n",
    "for i in range(examples):\n",
    "    x = torch.tensor([1])\n",
    "    one_hot_labels = auxiliares.get_one_hot_labels(x.to(device), n_classes)\n",
    "    fake_noise = auxiliares.get_noise(1, z_dim, device=device)\n",
    "    noise_and_labels = auxiliares.combine_vectors(fake_noise, one_hot_labels)\n",
    "    fake = gen(noise_and_labels)\n",
    "    fake = fake.cpu().detach().numpy()\n",
    "    \n",
    "    #fake = real[1].cpu().detach().numpy()\n",
    "    #fake = np.expand_dims(fake, axis=1)\n",
    "    \n",
    "    #real, label = myData.__getitem__(852)\n",
    "    #fake = real.cpu().detach().numpy()\n",
    "    #fake = np.expand_dims(fake, axis=1)\n",
    "    \n",
    "    fake = fake * std + mean\n",
    "    samplerate = 50\n",
    "    timee, muestra_rec=grifflin.reconstruir_señal_generador(fake, 1000, samplerate)\n",
    "    muestra_rec = np.squeeze(muestra_rec)\n",
    "    tamaño = len(muestra_rec) / samplerate\n",
    "    time = np.linspace(0., tamaño, len(muestra_rec))\n",
    "    plt.plot(time,muestra_rec)\n",
    "    plt.title(\"Señal Recuperada\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Red.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
