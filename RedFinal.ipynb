{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 1: Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1600,
     "status": "ok",
     "timestamp": 1651781428461,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "ti01SFhJ9mzS"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import RedFunciones.visualizacion as visualizacion\n",
    "import RedFunciones.Generador as Generador\n",
    "import RedFunciones.Discriminador as Discriminador\n",
    "import RedFunciones.auxiliares as auxiliares\n",
    "import RedFunciones.DataloaderVol as DataloaderVol\n",
    "import RedFunciones.Checkpoint as Checkpoint\n",
    "\n",
    "importlib.reload(auxiliares)\n",
    "importlib.reload(visualizacion)\n",
    "importlib.reload(Generador)\n",
    "importlib.reload(Discriminador)\n",
    "importlib.reload(DataloaderVol)\n",
    "importlib.reload(Checkpoint)\n",
    "\n",
    "import Auxiliares.BinaryAccuracy as bin_acc\n",
    "\n",
    "import json\n",
    "\n",
    "import PrePross.pre_pross as prpr\n",
    "import PrePross.grifflin as grifflin\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import importlib\n",
    "import pandas as pd\n",
    "importlib.reload(prpr)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import MNIST \n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "cuda0 = torch.device('cuda:0')\n",
    "cpu = 'cpu'\n",
    "device = torch.device(cuda0 if torch.cuda.is_available() else cpu)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5T2lKzKDm3W"
   },
   "source": [
    "Bloque 2:Pre Pros\n",
    "generar_nueva_base: Realizar el proceso de pre procesamiento y generar una nueva base pre procesada \n",
    "\n",
    "limite_snr: Limite de filtro de SNR en el pre procesamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generar_nueva_base = False\n",
    "if (generar_nueva_base):\n",
    "    limite_snr = 10\n",
    "    base_vt=prpr.open_bdd('Data/VT_IGEPN_1.json')\n",
    "    base_lp=prpr.open_bdd('Data/LP_IGEPN_1.json')\n",
    "    basef = pd.concat([base_vt, base_lp])\n",
    "    base=prpr.extraer_señales(basef, '')\n",
    "    prpr.normalizar_tamanio_base(base, 83)\n",
    "    prpr.normalizar_muestras(base, 8192/2)\n",
    "    base_rms=prpr.quitar_dc(basef)\n",
    "    base = base_rms\n",
    "    base = prpr.drop_data_na(base)\n",
    "    base = prpr.drop_data_ruido(base, limite_snr)\n",
    "    base = prpr.normailizar_muestras(base)\n",
    "    prpr.guardar_base_h5(base,129,33, nombre='baseSR10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 3: Semilla para resultados determinísticos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True  \n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "Z5T2lKzKDm3W"
   },
   "source": [
    "Bloque 4: Parámetros\n",
    "display_step: Frecuencia de visualización en el entrenamiento\n",
    "\n",
    "h5_filename: Ubicación de base de datos\n",
    "nombre: nombre base para guardar épocas checkpoints\n",
    "nombre_carga: nombre de checkpoint para cargar\n",
    "\n",
    "z_dim: Tamaño del vector de ruido que entra al discriminador\n",
    "n_epochs: número total de épocas a entrenar\n",
    "batch_size: tamaño del batch de entrenamiento\n",
    "\n",
    "Parámetros del optimizador del Generador:\n",
    "lrg, beta_1_g, beta_2_g \n",
    "repeats_g: número de iteraciones del generador por cada batch\n",
    "\n",
    "Parámetros del optimizador del Discriminador:\n",
    "lrd, beta_1_d, beta_2_d\n",
    "d_repeats : número de iteraciones del discriminador por cada batch\n",
    "\n",
    "guardar: guardar checkpoints de mantra regular \n",
    "cargar: cargar checkpoint\n",
    "save_steep: frecuencia de guardado de los checkpoints\n",
    "\n",
    "regularizaM: Aplicar regularización al Discriminador\n",
    "reg_lambda: parámetro de regularización L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 159,
     "status": "ok",
     "timestamp": 1651781431216,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "3yenniLFFfEP"
   },
   "outputs": [],
   "source": [
    "display_step = 250\n",
    "\n",
    "h5_filename = cwd + '/baseh5/baseSR10.h5'\n",
    "nombre = 'master'\n",
    "nombre_carga = 'final15.pt'\n",
    "\n",
    "z_dim = 64\n",
    "n_epochs = 15\n",
    "batch_size = 12\n",
    "\n",
    "lrg = 0.00009\n",
    "beta_1_g = 0.5\n",
    "beta_2_g = 0.999\n",
    "repeats_g = 3\n",
    "\n",
    "lrd = 0.0002\n",
    "beta_1_d = 0.5\n",
    "beta_2_d = 0.999\n",
    "d_repeats = 1\n",
    "\n",
    "guardar = False\n",
    "cargar = False\n",
    "save_steep = 1\n",
    "\n",
    "regularizaM = True\n",
    "reg_lambda = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 5: Constantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1651781434214,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "2jS27fJSj705"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "mnist_shape = (1, 129, 33) \n",
    "n_classes = 2\n",
    "mean = 0\n",
    "std = 1\n",
    "epoch_temp = -1\n",
    "gen_loss_temp = torch.empty([])\n",
    "disc_loss_temp = torch.empty([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 6: Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 165,
     "status": "ok",
     "timestamp": 1651781435932,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "eh7DtKHEHTY3"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([])    \n",
    "myData = DataloaderVol.VolcanoDatasetH5(h5_filename, transform)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    myData,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 7: Declaración de elementos de cGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4181,
     "status": "ok",
     "timestamp": 1651781442530,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "BQRA9L7sJVPU"
   },
   "outputs": [],
   "source": [
    "generator_input_dim, discriminator_im_chan = auxiliares.get_input_dimensions(z_dim, mnist_shape, n_classes)\n",
    "\n",
    "gen = Generador.Generator(input_dim=generator_input_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lrg)\n",
    "disc = Discriminador.Discriminator(im_chan=discriminator_im_chan).to(device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lrd)\n",
    "gen = gen.apply(auxiliares.weights_init)\n",
    "disc = disc.apply(auxiliares.weights_init)\n",
    "\n",
    "disc.train()\n",
    "gen.train()\n",
    "        \n",
    "metric = bin_acc.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 8: Carga checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1651781442531,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "Uwf8nslcSBWF"
   },
   "outputs": [],
   "source": [
    "if cargar:\n",
    "    compelto = Checkpoint.DIRECTORY + nombre_carga\n",
    "    checkpoint = torch.load(compelto)\n",
    "    gen.load_state_dict(checkpoint['gen'])\n",
    "    disc.load_state_dict(checkpoint['disc'])\n",
    "    gen_opt.load_state_dict(checkpoint['gen_opt'])\n",
    "    disc_opt.load_state_dict(checkpoint['disc_opt'])\n",
    "    epoch_temp = checkpoint['epoch']\n",
    "    gen_loss_temp = checkpoint['gen_loss']\n",
    "    disc_loss_temp = checkpoint['dis_loss']\n",
    "    print('Modelo cargado')\n",
    "    print('epoch: ' + str(epoch_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 9: Entrenamiento  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "executionInfo": {
     "elapsed": 812,
     "status": "error",
     "timestamp": 1651786992162,
     "user": {
      "displayName": "Christian Mauricio Yépez Escalante",
      "userId": "15071697346296237740"
     },
     "user_tz": 300
    },
    "id": "5dKjX-BpKq2s",
    "outputId": "503a6cc3-7017-46f1-d8fa-cd03722077fc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cur_step = 0\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "discriminator_losses_real = []\n",
    "discriminator_losses_fake = []\n",
    "metric_real = []\n",
    "metric_fake = [] \n",
    "\n",
    "for epoch in range(epoch_temp + 1, n_epochs):\n",
    "    print('Epoch: ' + str(epoch))\n",
    "    for real, labels in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "        one_hot_labels = auxiliares.get_one_hot_labels(labels.to(device), n_classes)\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = image_one_hot_labels.repeat(1, 1, mnist_shape[1], mnist_shape[2])\n",
    "        disc_opt.zero_grad()\n",
    "        fake_noise = auxiliares.get_noise(cur_batch_size, z_dim, device=device)\n",
    "        noise_and_labels = auxiliares.combine_vectors(fake_noise, one_hot_labels)\n",
    "        fake = gen.forward(noise_and_labels)    \n",
    "        #fake = gen(noise_and_labels)#gen.forward(noise_and_labels)\n",
    "        fake_image_and_labels = auxiliares.combine_vectors(fake.detach(), image_one_hot_labels)\n",
    "        real_image_and_labels = auxiliares.combine_vectors(real, image_one_hot_labels)\n",
    "        disc_fake_pred = disc(fake_image_and_labels)\n",
    "        disc_real_pred = disc(real_image_and_labels)               \n",
    "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "        metric_fake += [metric(disc_fake_pred, torch.zeros_like(disc_fake_pred)).item()]\n",
    "        metric_real += [metric(disc_real_pred, torch.ones_like(disc_real_pred)).item()]       \n",
    "        disc_loss = ((disc_fake_loss + disc_real_loss)/2)       \n",
    "        if regularizaM:\n",
    "            l2_reg = None\n",
    "            for W in disc.parameters():\n",
    "                if l2_reg is None:\n",
    "                    l2_reg = W.norm(2)\n",
    "                else:\n",
    "                    l2_reg = l2_reg + W.norm(2)\n",
    "            disc_loss = disc_loss +  l2_reg * reg_lambda         \n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        disc_opt.step() \n",
    "        discriminator_losses_real += [disc_real_loss.item()]\n",
    "        discriminator_losses_fake+= [disc_fake_loss.item()]\n",
    "        discriminator_losses += [disc_loss.item()]\n",
    "        mean_iteration_gen_loss = 0\n",
    "        for _ in range(repeats_g):\n",
    "            gen_opt.zero_grad()\n",
    "            fake_noise_2 = auxiliares.get_noise(cur_batch_size, z_dim, device=device)       \n",
    "            noise_and_labels_2 = auxiliares.combine_vectors(fake_noise_2, one_hot_labels)\n",
    "            fake_2 = gen(noise_and_labels_2)   \n",
    "            fake_image_and_labels = auxiliares.combine_vectors(fake_2, image_one_hot_labels)\n",
    "            disc_fake_pred = disc(fake_image_and_labels)\n",
    "            gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "            mean_iteration_gen_loss += gen_loss.item() / repeats_g    \n",
    "            gen_loss.backward()\n",
    "            gen_opt.step()\n",
    "        generator_losses += [mean_iteration_gen_loss]\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "            disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n",
    "            print(f\"Step {cur_step}: Generator loss: {gen_mean}, discriminator loss: {disc_mean}\")\n",
    "            print(f\"Espectrogramas Generados\")\n",
    "            visualizacion.show_tensor_images(torch.transpose(fake, 2, 3), size=(1, 129, 33), num_images=1)\n",
    "            print(f\"Espectrogramas Reales\")\n",
    "            visualizacion.show_tensor_images(torch.transpose(real, 2, 3), size=(1, 129, 33), num_images=1)\n",
    "            \n",
    "            visualizacion.show_time_domine_images(torch.transpose(real, 2, 3), size=(1, 129, 33), std=std, mean=mean, real = True)\n",
    "            visualizacion.show_time_domine_images(torch.transpose(fake, 2, 3), size=(1, 129, 33), std=std, mean=mean, real = False)\n",
    "            step_bins = 20\n",
    "            x_axis = sorted([i * step_bins for i in range(len(generator_losses) // step_bins)] * step_bins)\n",
    "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Generator Loss\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Discriminator Loss\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Generator Loss\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(discriminator_losses_fake[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Discriminator Loss Fake\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(discriminator_losses_real[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Discriminator Loss Real\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(metric_real[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"METRIC REAL\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(metric_fake[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"METRIC FAKE\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        elif cur_step == 0:\n",
    "            print(\"Red Funcionando\")\n",
    "        cur_step += 1 \n",
    "    if((guardar and epoch % save_steep == 0) or epoch == n_epochs - 1):\n",
    "        Checkpoint.save_weighs(gen, disc, gen_opt, disc_opt, epoch, gen_loss, disc_loss, nombre)\n",
    "        print('epoch guardada')\n",
    "gen.eval()\n",
    "disc.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 10: Generación de ejemplos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUTT5mStj71B",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import PrePross.grifflin as grifflin\n",
    "import numpy as np\n",
    "\n",
    "examples = 3\n",
    "\n",
    "for i in range(examples):\n",
    "    x = torch.tensor([1])\n",
    "    one_hot_labels = auxiliares.get_one_hot_labels(x.to(device), n_classes)\n",
    "    fake_noise = auxiliares.get_noise(1, z_dim, device=device)\n",
    "    noise_and_labels = auxiliares.combine_vectors(fake_noise, one_hot_labels)\n",
    "    fake = gen(noise_and_labels)\n",
    "    fake = fake.cpu().detach().numpy() \n",
    "    fake = fake * std + mean\n",
    "    samplerate = 50\n",
    "    timee, muestra_rec=grifflin.reconstruir_señal_generador(fake, 1000, samplerate)\n",
    "    muestra_rec = np.squeeze(muestra_rec)\n",
    "    tamaño = len(muestra_rec) / samplerate\n",
    "    time = np.linspace(0., tamaño, len(muestra_rec))\n",
    "    plt.plot(time,muestra_rec)\n",
    "    plt.title(\"Señal Recuperada\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()\n",
    "    x = torch.tensor([0])\n",
    "    one_hot_labels = auxiliares.get_one_hot_labels(x.to(device), n_classes)\n",
    "    fake_noise = auxiliares.get_noise(1, z_dim, device=device)\n",
    "    noise_and_labels = auxiliares.combine_vectors(fake_noise, one_hot_labels)\n",
    "    fake = gen(noise_and_labels)\n",
    "    fake = fake.cpu().detach().numpy() \n",
    "    fake = fake * std + mean\n",
    "    samplerate = 50\n",
    "    timee, muestra_rec=grifflin.reconstruir_señal_generador(fake, 1000, samplerate)\n",
    "    muestra_rec = np.squeeze(muestra_rec)\n",
    "    tamaño = len(muestra_rec) / samplerate\n",
    "    time = np.linspace(0., tamaño, len(muestra_rec))\n",
    "    plt.plot(time,muestra_rec)\n",
    "    plt.title(\"Señal Recuperada\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 11: Generación de muestras para calcular FID y calculo de la métrica FID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "n = 4792\n",
    "for i in range(n):\n",
    "    x = torch.tensor([1])\n",
    "    one_hot_labels = auxiliares.get_one_hot_labels(x.to(device), n_classes)\n",
    "    fake_noise = auxiliares.get_noise(1, z_dim, device=device)\n",
    "    noise_and_labels = auxiliares.combine_vectors(fake_noise, one_hot_labels)\n",
    "    fake = gen(noise_and_labels)\n",
    "    nombre = 'img/fake/lp/img'+str(i)+'.png'\n",
    "    save_image(fake, nombre)\n",
    "\n",
    "n = 1358\n",
    "for i in range(n):\n",
    "    x = torch.tensor([0])\n",
    "    one_hot_labels = auxiliares.get_one_hot_labels(x.to(device), n_classes)\n",
    "    fake_noise = auxiliares.get_noise(1, z_dim, device=device)\n",
    "    noise_and_labels = auxiliares.combine_vectors(fake_noise, one_hot_labels)\n",
    "    fake = gen(noise_and_labels)\n",
    "    nombre = 'img/fake/vt/img'+str(i)+'.png'\n",
    "    save_image(fake, nombre)\n",
    "\n",
    "n = 1000\n",
    "for i in range(n):\n",
    "    ruidoplano = np.random.normal(size = 129*33)\n",
    "    ruido = ruidoplano.reshape((129, 33))\n",
    "    nombre = 'img/ruido/img'+str(i)+'.png'\n",
    "    sample = torch.from_numpy(ruido)\n",
    "    save_image(sample, nombre)\n",
    "\n",
    "n = myData.__len__()\n",
    "c =0\n",
    "cd=0\n",
    "for i in range(n):\n",
    "    sample, tag = myData.__getitem__(i)\n",
    "    nombre = ''\n",
    "    if tag == 0:\n",
    "        nombre = 'img/real/vt/img'+str(i)+'.png'\n",
    "        save_image(sample, nombre)\n",
    "    if tag == 1:\n",
    "        nombre = 'img/real/lp/img'+str(i)+'.png'\n",
    "        save_image(sample, nombre)\n",
    "!python -m pytorch_fid img/fake/vt img/real/vt\n",
    "!python -m pytorch_fid img/fake/lp img/real/lp\n",
    "!python -m pytorch_fid img/fake/vt img/ruido\n",
    "!python -m pytorch_fid img/fake/lp img/ruido\n",
    "!python -m pytorch_fid img/fake/vt img/fake/lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 12: Generar base de datos de n muestras de cada tipo\n",
    "numOfSamples: número de muestras de cada tipo a generar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "fileName = 'baseh5/' + 'base_final' + '.h5'\n",
    "numOfSamples = 10000\n",
    "with h5py.File(fileName, \"w\") as out:\n",
    "    dt = h5py.special_dtype(vlen=str)\n",
    "    out.create_dataset(\"X_esp\", (2*numOfSamples, 129, 33), dtype='float64')\n",
    "    out.create_dataset(\"X_time\", (2*numOfSamples, 4096, 1), dtype='float64')\n",
    "    out.create_dataset(\"X_tag\", (2*numOfSamples, 1), dtype=dt)\n",
    "with h5py.File(fileName, \"a\") as out:\n",
    "    for i in range(numOfSamples):\n",
    "        x = torch.tensor([0])\n",
    "        one_hot_labels = auxiliares.get_one_hot_labels(x.to(device), n_classes)\n",
    "        fake_noise = auxiliares.get_noise(1, z_dim, device=device)\n",
    "        noise_and_labels = auxiliares.combine_vectors(fake_noise, one_hot_labels)\n",
    "        fake = gen(noise_and_labels)\n",
    "        fake = fake.cpu().detach().numpy() \n",
    "        fake = fake * std + mean\n",
    "        samplerate = 50\n",
    "        timee, muestra_rec=grifflin.reconstruir_señal_generador(fake, 1000, samplerate)\n",
    "        out['X_esp'][i, ...] = fake\n",
    "        out['X_time'][i, ...] = np.squeeze(muestra_rec).reshape(4096, 1)\n",
    "        out['X_tag'][i, ...] = 'VT'        \n",
    "        x = torch.tensor([1])\n",
    "        one_hot_labels = auxiliares.get_one_hot_labels(x.to(device), n_classes)\n",
    "        fake_noise = auxiliares.get_noise(1, z_dim, device=device)\n",
    "        noise_and_labels = auxiliares.combine_vectors(fake_noise, one_hot_labels)\n",
    "        fake = gen(noise_and_labels)\n",
    "        fake = fake.cpu().detach().numpy() \n",
    "        fake = fake * std + mean\n",
    "        timee, muestra_rec=grifflin.reconstruir_señal_generador(fake, 1000, samplerate)\n",
    "        out['X_esp'][i + 10000, ...] = fake\n",
    "        out['X_time'][i + 10000, ...] = np.squeeze(muestra_rec).reshape(4096, 1)\n",
    "        out['X_tag'][i + 10000, ...] = 'LP'\n",
    "        if(i%10 == 0):\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Red.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
